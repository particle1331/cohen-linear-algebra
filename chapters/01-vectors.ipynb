{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectors and matrices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (1.1) **No. of linearly independent vectors in ${\\mathbb R^m}$**.  The maximum length $n$ of a list of linearly independent vectors in $\\mathbb R^m$ is bounded by $m$.  If $n > m$, then the list is linearly dependent. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - (1.2) **Complexity of checking independence**.\n",
    "  Suppose $n \\leq m.$ What is the time complexity of showing n vectors in $\\mathbb R^m$ are linearly independent? i.e. solving for nonzero solutions to $\\mathbf A\\mathbf x = \\mathbf 0$. For instance, we have $\\mathcal{O}(\\frac{2}{3} mn^2)$ using Gaussian elimination assuming $\\mathcal{O}(1)$ arithmetic which is a naive assumption as careless implementation can easily create numbers that can be [exponentially large](https://cstheory.stackexchange.com/questions/3921/what-is-the-actual-time-complexity-of-gaussian-elimination)! In practice, the best way to compute the rank of $\\mathbf A$ is through its SVD. This is, for example, how `numpy.linalg.matrix_rank` is implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.3 (main, Mar 26 2022, 10:14:30) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "74fc4d732c045e64e902852b64fc2bd2168aa0e65c0f64395f775ce1c5c468e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
